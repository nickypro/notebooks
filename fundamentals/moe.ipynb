{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize as sk_normalize\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from taker import Model\n",
    "\n",
    "\n",
    "def cluster_neurons(model: Model,\n",
    "        layer: int,\n",
    "        split_num: int=96,\n",
    "        method=\"kmeans\",\n",
    "    ):\n",
    "    # First, get variables for which components are used\n",
    "    assert model.cfg.d_mlp % split_num == 0, \\\n",
    "        \"split_num should evenly divide model's mlp width\"\n",
    "    split_size = model.cfg.d_mlp // split_num\n",
    "\n",
    "    # Collect the neurons we are clustering\n",
    "    weights = model.layers[layer][\"mlp.W_in\"].detach().cpu()\n",
    "    normed_weights = sk_normalize(weights)\n",
    "\n",
    "    # Perform the clustering\n",
    "    if method == \"kmeans\":\n",
    "        kmeans = KMeansConstrained(\n",
    "            n_clusters=split_num, size_min=split_size, size_max=split_size, random_state=0\n",
    "        ).fit(normed_weights, None)\n",
    "        labels = [x for x in kmeans.labels_]\n",
    "        return labels, kmeans\n",
    "\n",
    "    if method == \"random\":\n",
    "         labels = np.array(list(range(model.cfg.d_mlp))) % split_num\n",
    "         return labels, {}\n",
    "\n",
    "    raise NotImplementedError(f\"method {method} not implemented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded nickypro/tinyllama-15m\n",
      " - Registered 6 Attention Layers\n",
      "[91, 35, 6, 33, 82, 28, 1, 76, 59, 25, 61, 55, 66, 91, 49, 55, 93, 37, 33, 24, 38, 92, 80, 32, 21, 26, 75, 76, 73, 31, 42, 4, 15, 11, 76, 0, 3, 91, 36, 72, 4, 59, 44, 35, 11, 23, 58, 54, 3, 50, 69, 94, 19, 56, 47, 92, 94, 62, 80, 66, 12, 23, 86, 32, 80, 79, 17, 86, 40, 13, 44, 17, 47, 1, 59, 25, 55, 72, 5, 43, 69, 27, 94, 76, 71, 45, 11, 22, 56, 69, 64, 29, 3, 2, 39, 24, 41, 32, 5, 90, 94, 63, 39, 38, 29, 8, 57, 88, 63, 86, 49, 87, 64, 7, 21, 16, 36, 87, 8, 3, 33, 11, 12, 93, 50, 81, 78, 85, 48, 27, 45, 91, 62, 70, 51, 47, 31, 52, 43, 70, 18, 55, 61, 68, 67, 55, 93, 17, 8, 41, 2, 81, 37, 62, 16, 41, 16, 73, 52, 46, 74, 5, 72, 65, 43, 42, 10, 59, 49, 69, 19, 52, 31, 18, 77, 84, 44, 24, 7, 21, 13, 3, 26, 14, 34, 87, 46, 75, 39, 57, 14, 75, 71, 68, 89, 54, 10, 30, 57, 85, 12, 20, 56, 10, 82, 57, 90, 51, 31, 15, 35, 58, 47, 62, 72, 65, 9, 76, 89, 22, 9, 19, 64, 49, 11, 45, 9, 82, 72, 72, 5, 43, 12, 91, 31, 79, 61, 29, 87, 54, 83, 85, 84, 83, 9, 80, 76, 94, 65, 21, 92, 57, 38, 48, 18, 50, 36, 46, 2, 34, 34, 32, 17, 92, 23, 93, 18, 72, 2, 22, 33, 45, 49, 40, 63, 73, 47, 35, 75, 79, 10, 41, 28, 94, 6, 14, 86, 64, 20, 4, 53, 58, 56, 95, 20, 52, 78, 77, 88, 19, 26, 0, 26, 22, 39, 22, 44, 95, 83, 19, 53, 82, 88, 57, 72, 33, 49, 17, 38, 58, 42, 13, 18, 44, 80, 20, 66, 12, 58, 81, 13, 83, 37, 40, 53, 40, 18, 91, 27, 10, 14, 39, 39, 88, 27, 6, 62, 52, 74, 63, 89, 52, 63, 15, 53, 0, 30, 21, 33, 28, 81, 77, 30, 14, 73, 37, 71, 51, 27, 31, 71, 43, 24, 74, 46, 30, 28, 17, 83, 59, 65, 4, 38, 1, 74, 23, 84, 27, 60, 88, 75, 7, 48, 59, 28, 1, 48, 30, 64, 83, 54, 48, 5, 14, 79, 13, 14, 66, 94, 45, 87, 2, 46, 31, 8, 89, 60, 67, 68, 45, 41, 47, 10, 26, 4, 29, 0, 78, 78, 35, 17, 68, 16, 26, 64, 67, 25, 51, 85, 78, 7, 59, 39, 54, 69, 16, 15, 60, 21, 79, 2, 7, 79, 74, 65, 21, 61, 62, 77, 11, 90, 37, 87, 85, 27, 36, 45, 86, 43, 5, 23, 57, 49, 24, 75, 6, 81, 92, 73, 95, 34, 56, 35, 80, 63, 34, 69, 56, 36, 83, 93, 70, 46, 64, 38, 89, 77, 53, 62, 87, 86, 21, 77, 83, 82, 90, 43, 30, 32, 65, 69, 40, 12, 77, 55, 22, 86, 4, 39, 9, 85, 44, 18, 29, 95, 15, 95, 24, 4, 45, 95, 67, 89, 19, 66, 9, 34, 50, 75, 55, 70, 32, 49, 47, 58, 0, 28, 5, 82, 84, 51, 15, 44, 10, 53, 51, 68, 85, 60, 2, 48, 27, 34, 25, 67, 22, 40, 1, 63, 3, 26, 40, 7, 74, 46, 95, 90, 60, 25, 88, 81, 6, 78, 37, 56, 47, 81, 20, 79, 48, 20, 32, 82, 28, 90, 81, 54, 37, 25, 86, 63, 56, 2, 65, 22, 78, 78, 4, 29, 13, 7, 8, 43, 8, 8, 80, 0, 92, 37, 25, 6, 76, 0, 71, 11, 66, 29, 69, 71, 73, 40, 3, 93, 62, 50, 54, 74, 71, 54, 84, 64, 75, 61, 26, 35, 23, 42, 32, 42, 65, 84, 41, 50, 10, 58, 53, 29, 9, 60, 60, 85, 11, 42, 33, 59, 16, 15, 44, 91, 20, 73, 15, 30, 6, 42, 89, 67, 76, 95, 13, 52, 61, 33, 51, 18, 93, 93, 36, 31, 7, 41, 90, 13, 30, 89, 48, 38, 41, 70, 80, 28, 24, 88, 20, 1, 87, 36, 79, 19, 5, 34, 23, 90, 73, 8, 88, 84, 70, 24, 61, 66, 53, 9, 92, 92, 17, 57, 42, 1, 68, 84, 36, 70, 16, 1, 19, 6, 50, 94, 23, 12, 3, 67, 67, 12, 55, 25, 74, 14, 71, 58, 51, 0, 61, 70, 35, 77, 68, 46, 82, 16, 50, 60, 68, 38, 66, 91, 52]\n"
     ]
    }
   ],
   "source": [
    "m = Model(\"nickypro/tinyllama-15m\")\n",
    "\n",
    "for layer in range(1):\n",
    "    labels, _ = cluster_neurons(m, layer, method=\"kmeans\")\n",
    "    print(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
