{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to prune neurons?\n",
    "- Maybe by replace activations with zero?\n",
    "- Maybe with replace activations with random? What is random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from taker import Model\n",
    "from taker.eval import evaluate_all\n",
    "from taker.data_classes import PruningConfig, RunDataHistory\n",
    "from taker.prune import prune_random\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "def run_random_replacement(m: Model, c: PruningConfig, sampled_text: str):\n",
    "    # Prepare data logging\n",
    "    history = RunDataHistory(c.datasets)\n",
    "    wandb.init(\n",
    "        project=c.wandb_project,\n",
    "        entity=c.wandb_entity,\n",
    "        name=c.wandb_run_name,\n",
    "        )\n",
    "    wandb.config.update(c.to_dict(), allow_val_change=True)\n",
    "\n",
    "    # Get the random activations we will be replacing with\n",
    "    preout_rand = m.get_attn_pre_out_activations(sampled_text)\n",
    "\n",
    "    # evaluate the modified model\n",
    "    if c.run_pre_test:\n",
    "        data = evaluate_all(m, c.eval_sample_size,\n",
    "            c.datasets, c.collection_sample_size)\n",
    "        history.add(data)\n",
    "        print(history.df.T)\n",
    "\n",
    "    # run all the steps of pruning\n",
    "    ff_pruned, attn_pruned = None, None\n",
    "    for i in tqdm(range(c.n_steps)):\n",
    "        # prune some neurons\n",
    "        ff_pruned, attn_pruned, misc = \\\n",
    "            prune_random(m, attn_frac=c.attn_frac, ff_frac=c.ff_frac, ff_pruned=ff_pruned, attn_pruned=attn_pruned)\n",
    "\n",
    "        # update the pruned neurons to be resampled\n",
    "        preout_rand_masked = m.run_inverse_masking(preout_rand, \"attn_pre_out\")\n",
    "        m.update_actadd(preout_rand_masked.reshape(m.cfg.n_layers, m.limit, m.cfg.d_model), \"attn_pre_out\")\n",
    "\n",
    "        # evaluate the modified model\n",
    "        data = evaluate_all(m, c.eval_sample_size,\n",
    "            [c.focus], c.collection_sample_size)\n",
    "        history.add(data)\n",
    "        print(history.df.T)\n",
    "\n",
    "    wandb.finish()\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = \"\"\"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\"\"\"\n",
    "\n",
    "c = PruningConfig(\n",
    "    model_repo = \"facebook/opt-1.3b\",\n",
    "    token_limit= 1000,\n",
    "    dtype = \"fp16\",\n",
    "    wandb_run_name = \"opt-1.3b 5% resampling rand chars\",\n",
    "    wandb_project = \"nicky-resampling-testing\",\n",
    "    focus = \"pile\",\n",
    "    cripple=\"code\",\n",
    "    collection_sample_size = 1e4,\n",
    "    eval_sample_size = 1e5,\n",
    "    ff_frac = 0.00,\n",
    "    attn_frac = 0.05,\n",
    "    n_steps = 20,\n",
    ")\n",
    "\n",
    "m = Model(c.model_repo, limit=c.token_limit, dtype=c.dtype)\n",
    "#run_random_replacement(m, c, random_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rand_image = np.random.randint(0, 255, [3, 244, 244])\n",
    "print(m.processor(rand_image)[\"pixel_values\"][0].shape)\n",
    "\n",
    "c = PruningConfig(\n",
    "    model_repo = \"google/vit-base-patch16-224\",\n",
    "    token_limit= 1000,\n",
    "    dtype = \"fp32\",\n",
    "    wandb_run_name = \"vit 10% resampling rand pixels\",\n",
    "    wandb_project = \"nicky-resampling-testing\",\n",
    "    focus = \"imagenet-1k\",\n",
    "    cripple=\"imagenet-1k-birds\",\n",
    "    collection_sample_size = 1e4,\n",
    "    eval_sample_size = 1e4,\n",
    "    ff_frac = 0.00,\n",
    "    attn_frac = 0.10,\n",
    "    n_steps = 10,\n",
    ")\n",
    "\n",
    "m = Model(c.model_repo, limit=c.token_limit, dtype=c.dtype)\n",
    "run_random_replacement(m, c, rand_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
