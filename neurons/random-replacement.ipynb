{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to prune neurons?\n",
    "- Maybe by replace activations with zero?\n",
    "- Maybe with replace activations with random? What is random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_input = \"\"\"\n",
    "3KhCfVVkC5VNSchVtAyKurMGCHaMHS25\n",
    "SSKrJRD6yaNZSwSN3MsVBRNs6KmvQG3q\n",
    "YFntXDqxWtBKDcNHcDmHuRbNa39qWc7w\n",
    "hK2LZPXKxUP8qWfmKfCEyfEzcUWJMDca\n",
    "Hve9qM7BGfurBeNCDryd7Ad2Rc2VYxym\n",
    "X4DGeuJZ8Thq4C3jjUAeAPpCn7wQZVeL\n",
    "x9A35JypdKTvgYGQKvfD6bgK3hVfq8tH\n",
    "hnDUWuTQppnBn4VTMFhYTK9A5dLHyqp9\n",
    "p5uCpD4uBzFJH2Yx4GGg5uwt6uCuVS2P\n",
    "fD239awAbXRh7euz3EzFVBC7eeSmeMz2\n",
    "Np5YEW8Ra5x26pqQvw897CRJjbmm3RxN\n",
    "cmYJqUFFwRPVAQrbVTHxfPQtf4R9NCJz\n",
    "fRGHRfNcQ9ZD9UapmNmfcXEKre8sBtyD\n",
    "nSpjET6nhDnqfdC79Qd4mSEQnSNyk2FK\n",
    "PkRbd4mpgyahgNTJh4ZcWY8SpVab8jMv\n",
    "BTA9yFmKJmtKTzcpvgdyy7HbbAyDZRzt\n",
    "CuC5Jw5VLExnJgLX7Wath49LcL4qEJmC\n",
    "7w335MF9hGaYY9s7nQwbAzpARReC3Edf\n",
    "jVzxd7f2ru64f8Zb8KJr6JeUprrqyaQz\n",
    "fm9wtL2hFkxprUc5vGnJP3fghyNNeUFS\n",
    "3bsDEnbFVJaYGYnQBWeLtm74Fp4HMyhQ\n",
    "YFXeVY4EFwSYMRCCLdd3pACADcZ5LjSr\n",
    "BTR9ryHMACxU5uhM7JTGRW9sAzzfM26W\n",
    "2vzuvGWjTFDsVfYWrAzvnm56C5wstVeT\n",
    "y9sEexYkCwag3MEGxr3qnJpQYESPZuMt\n",
    "EhhjeFTBnaMaZ2HJNHfEj2WkJXNGPjF4\n",
    "qsv48r3tEk462nDQ7UhTRcZvnDwAMSgF\n",
    "tv6PX2HXz8EqzCv2jgYUFvgajXjfmK9k\n",
    "zy9bjLaSyG6qSrSMWFWhLkwLWrednXdW\n",
    "FE822FCqNK8vsCxtpWpVCYK7C42gy7DF\n",
    "mFffPa53XWdT69UNefXumy5FGtqRasfr\n",
    "sA3yNr96uRSnBsjTSDyA7uLfxeWCcu87\n",
    "w7MXtQVXuNR9g9EXmNmLUR5nEWPjVsf2\n",
    "C8AdARb5q4VqafTZMYhxBUFcp2DNQf6Z\n",
    "7kFrJrC9kU4Lrmt4TUhr93EN28Wx4Mr6\n",
    "pGn8bqfvttLYW7KpWFxMwjHfnreh53ZB\n",
    "MHG477QV9qYmXYweN5uXe4Zd2Q94mGFu\n",
    "w9B2uzLsSqMGq9ZUGAfGtbmzn3ybn6dC\n",
    "bDwdQ8XhkBxJSHfTHxncNLEdPPkKvsjR\n",
    "RNUcBELxE48ChL36fUWWWcJtxYCuA9zv\n",
    "cMhFPHD8MBY3cX4qwN8vpcRCADM7g9px\n",
    "2J2ceK9MVTXEdJd93haQZG6E8eGLgbWt\n",
    "27jjR7rXYAaqm9uDuVLMgDLK9uMNhjAt\n",
    "sY89ymz9hvPeM7bGYKvCwfb8GujfKQAV\n",
    "w2JmRFHUQP4hBfDT9ccSG9Wd8mQUuGmV\n",
    "YVpEbUZfRQZ8wmqPkGQjSZZDU9XLWSzy\n",
    "NAgvZHXvpCbBYFzWtQPefsVsC6sD64Ta\n",
    "qyHRmTxftS24QWmZzVMcemUhbfgZTxqu\n",
    "kg7CGfNL4S4cHPFhV7n2hBxDXDNLRyYM\n",
    "4ZAQX5m9phCqPnTQw8T9wKwEhnm2pRLw\n",
    "2D748S89SSv5LYLUMXeVeG6EAZRtuyuD\n",
    "QbPJvRF3EK6zvJvqV5QtWVpkveQMU6xq\n",
    "757F97h5Af8vmM58t7k9U6GAr4RvFFZ6\n",
    "WnYkQVXE74MXw4HLWJwnCu3YevDaSNNJ\n",
    "EeFqkmEGk3wnkrVyN8AKShTBLcrtw7qa\n",
    "WQktwdF9qRqF2Zf58ZC3suUg9B76TPD9\n",
    "nh3fFpMUuSQAwYzF8CH4zzRD2tV3F5zj\n",
    "xEKmnCpxdERCKgRSYX6KWRrnFwhuEp25\n",
    "vQaYUp4mCnXbgd6AVkUzVv64JnbC7Yxp\n",
    "23gpv5NYp6vfJCFuzRwaMbE6RRurKHP6\n",
    "FQ9j9KbSTx3CmgThn4Zfv39q2u6AfrBW\n",
    "m5sPpQQeh666FqFxGfAq7ttA8x8JPSMH\n",
    "5dh7EkjFhhxrQRBWMrSCHLMM3b9TzXKK\n",
    "ANm2BruU43uW397dKw9vytSkbxS9AkAN\n",
    "6rbAxuY96SdwfN4vLHm7hU7nEDvkWt7S\n",
    "n7jETEfSRTj9upFgxwKpn3nHkZ43zYCz\n",
    "WdthZRfN5m5WwdNYDgMbjAvZNCjgUyC6\n",
    "FT9nhMhJ7XChJG5q4u7Aa2PUMF6QNrqa\n",
    "MmuAEnZNdPCq7544ZdaW9vej59GqhUJn\n",
    "KHU9pfSwKbRt4wYV4de6JwmMkAFuawbn\n",
    "FXkYyCDCfmJAt3fJDNyuZpzXbPxreHgC\n",
    "Q6dSMqrD6P4w8nUK99eFHeLfhdUCy4Aa\n",
    "fDskbZrqb7P4ZWqMVPL8K2HqfEYSYMrf\n",
    "sXnyZ87RQ3fxSLMfym5SyzX9E8x3zKsv\n",
    "rRTWpGCbrYgVf3GszHUkCGuSkpfPW3xH\n",
    "krknS73Rzt4DWjZTpx63C8zTPHyyuVTG\n",
    "qSFHkwa9McvSPtmK8v9VeU7HydWEdvxk\n",
    "xLvPhhYa2QwUqCQut4gRSXTjfRWv8r4e\n",
    "jkq3vwrjnEJDv2HNEf7yqm3gVR2Hq7Zr\n",
    "vm35QLghBDsKxJXEM9S8wFNrVTUAvjs9\n",
    "muaD42eDfqn6uCNKrYPTw44Q9gzHW5mE\n",
    "WfEtEWk2wj26FAzxZMmnvxuFsU3Yucdb\n",
    "H2vXqB86dUWRucMqcjfg8FDBMDwdmcUr\n",
    "ENNTUEdPtwhqSRN5hyWKPjGTxQSzuCx9\n",
    "VSpjn2k6LFzE3YKTLxXNz4UgTM4X98CD\n",
    "Zkat6pFXwudGUucLFQgsh95g4BjbKTTH\n",
    "vCUfMfQhB8Qxuz2MkGtKSbAfNLFYd65K\n",
    "y6fq6hkHqQZHFYFKu6jDdU3ZJup9zUSK\n",
    "49gDBDZnqQGgSraZkUKnTEdwVqAWaTWN\n",
    "D28nXSCmzvUUYvmrYqZR6fVqqk7dcEFN\n",
    "duksGqqce8LXRhzesSGCmunpGWY4ewQY\n",
    "afK79yU7GMm8ZFnaZ4Ur2xA2PfDksu2M\n",
    "PJhv5X2fyNwRQPHhZjsQJJtedcx5Ktt7\n",
    "kuqYWxwt5SP5CpAbLNr3V4xGmMMCsrEr\n",
    "rnXsS37decqMxW2TKxrTNJDUxvuMPaXA\n",
    "Z3zVRbVa72DQ2vcNBKx423Zn3GXcqUhk\n",
    "zaKEXhY79w4D7ejMrHhNeG7HJfwHzPDV\n",
    "pG5SQPZPK37AWHeu2rNjkArVYLRNXepD\n",
    "fwPhRX2jCKWSTQMxwcswNJEcsMhA8HEh\n",
    "vBpRUMktY9dh7mZpAfkT5VyVXSQh3Dns\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/taker/src/taker/model.py:143: UserWarning: Model facebook/galactica-125m not tested.\n",
      "  warnings.warn( f\"Model {model_repo} not tested.\" )\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16253d294e5741fead1700ce51282566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/787 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20530099f69469d9bc869993689d3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/166 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df83a12e5dc74bb1a21db595a013eb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.14M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9d1330aa8042e083264bba65987798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/3.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922a3565861f4275adedc22ee4454942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/250M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b40a4ca27ea4b6eaae6e8df75830993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded facebook/galactica-125m\n",
      " - Registered 12 Attention Layers\n",
      "odict_keys(['layers.0.param', 'layers.0.offset', 'layers.1.param', 'layers.1.offset', 'layers.2.param', 'layers.2.offset', 'layers.3.param', 'layers.3.offset', 'layers.4.param', 'layers.4.offset', 'layers.5.param', 'layers.5.offset', 'layers.6.param', 'layers.6.offset', 'layers.7.param', 'layers.7.offset', 'layers.8.param', 'layers.8.offset', 'layers.9.param', 'layers.9.offset', 'layers.10.param', 'layers.10.offset', 'layers.11.param', 'layers.11.offset'])\n"
     ]
    }
   ],
   "source": [
    "from taker import Model\n",
    "\n",
    "m = Model(\"facebook/galactica-125m\", limit=1000)\n",
    "\n",
    "print(m.masks[\"mlp_pre_out\"].state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1000, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "apo_rand = m.get_attn_pre_out_activations(random_input)\n",
    "print(apo_rand.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2336bc26535d4745b402651efa403713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 76.43|49.73 (Skip: 69.67|43.13): : 100410it [05:30, 303.92it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_data': {'pile': {'perplexity': nan,\n",
       "   'loss': 2.6816,\n",
       "   'log_loss': -0.5583}},\n",
       " 'accuracy': {'pile': {'base': 49.72670359662481,\n",
       "   'topk': 76.433978504116,\n",
       "   'skip': 43.13215815157853,\n",
       "   'topk_skip': 69.67433522557515}},\n",
       " 'misc': {'pile': {'accuracy_data': {'num_predictions': 135933,\n",
       "    'num_accurate': 67595,\n",
       "    'num_topk_accurate': 103899,\n",
       "    'num_skip_predictions': 100410,\n",
       "    'num_skip_accurate': 43309,\n",
       "    'num_topk_skip_accurate': 69960,\n",
       "    'token_counts': array([0., 0., 0., ..., 0., 0., 0.])},\n",
       "   'eval_config': {'dataset_name': 'pile',\n",
       "    'dataset_repo': 'monology/pile-uncopyrighted',\n",
       "    'dataset_subset': None,\n",
       "    'dataset_type': 'prediction',\n",
       "    'dataset_text_key': 'text',\n",
       "    'dataset_text_label_key': 'label',\n",
       "    'dataset_filter': None,\n",
       "    'dataset_has_test_split': True,\n",
       "    'dataset_split': None,\n",
       "    'streaming': True,\n",
       "    'sample_size': 100000.0,\n",
       "    'skip_token_strings': ['The',\n",
       "     'are',\n",
       "     'it',\n",
       "     '\\\\',\n",
       "     '*',\n",
       "     '-',\n",
       "     '  ',\n",
       "     'by',\n",
       "     '=',\n",
       "     ';',\n",
       "     'ing',\n",
       "     'was',\n",
       "     'as',\n",
       "     'be',\n",
       "     'on',\n",
       "     '/',\n",
       "     \"'\",\n",
       "     '(',\n",
       "     '               ',\n",
       "     'with',\n",
       "     '\\t',\n",
       "     '7',\n",
       "     'for',\n",
       "     'that',\n",
       "     ':',\n",
       "     '8',\n",
       "     ')',\n",
       "     '6',\n",
       "     's',\n",
       "     '9',\n",
       "     '(',\n",
       "     'is',\n",
       "     '5',\n",
       "     '4',\n",
       "     '_',\n",
       "     '3',\n",
       "     'in',\n",
       "     'a',\n",
       "     '-',\n",
       "     'to',\n",
       "     'and',\n",
       "     '2',\n",
       "     'of',\n",
       "     '1',\n",
       "     '0',\n",
       "     '',\n",
       "     'the',\n",
       "     ',',\n",
       "     '.',\n",
       "     '\\n'],\n",
       "    'skip_token_ids': [tensor(305, device='cuda:0'),\n",
       "     tensor(82, device='cuda:0'),\n",
       "     tensor(304, device='cuda:0'),\n",
       "     tensor(315, device='cuda:0'),\n",
       "     tensor(2600, device='cuda:0'),\n",
       "     tensor(1394, device='cuda:0'),\n",
       "     tensor(31, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(85, device='cuda:0'),\n",
       "     tensor(862, device='cuda:0'),\n",
       "     tensor(637, device='cuda:0'),\n",
       "     tensor(49, device='cuda:0'),\n",
       "     tensor(317, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(37, device='cuda:0'),\n",
       "     tensor(2388, device='cuda:0'),\n",
       "     tensor(4871, device='cuda:0'),\n",
       "     tensor(44, device='cuda:0'),\n",
       "     tensor(297, device='cuda:0'),\n",
       "     tensor(41, device='cuda:0'),\n",
       "     tensor(480, device='cuda:0'),\n",
       "     tensor(39, device='cuda:0'),\n",
       "     tensor(38, device='cuda:0'),\n",
       "     tensor(221, device='cuda:0'),\n",
       "     tensor(36, device='cuda:0'),\n",
       "     tensor(592, device='cuda:0'),\n",
       "     tensor(2182, device='cuda:0'),\n",
       "     tensor(29, device='cuda:0'),\n",
       "     tensor(220, device='cuda:0'),\n",
       "     tensor(48, device='cuda:0'),\n",
       "     tensor(105, device='cuda:0'),\n",
       "     tensor(43, device='cuda:0'),\n",
       "     tensor(280, device='cuda:0'),\n",
       "     tensor(40, device='cuda:0'),\n",
       "     tensor(34, device='cuda:0'),\n",
       "     tensor(51, device='cuda:0'),\n",
       "     tensor(283, device='cuda:0'),\n",
       "     tensor(32, device='cuda:0'),\n",
       "     tensor(2451, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(45, device='cuda:0'),\n",
       "     tensor(46, device='cuda:0'),\n",
       "     tensor(47, device='cuda:0'),\n",
       "     tensor(42, device='cuda:0'),\n",
       "     tensor(87, device='cuda:0'),\n",
       "     tensor(947, device='cuda:0'),\n",
       "     tensor(831, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(12369, device='cuda:0')],\n",
       "    'topk': 10,\n",
       "    'start_index': 0,\n",
       "    'num_texts_to_skip': 0,\n",
       "    'num_tokens_to_skip': 0,\n",
       "    'num_top_tokens': 50,\n",
       "    'loading_bar_desc': 'Acc',\n",
       "    'verbose': False,\n",
       "    'is_train_mode': False,\n",
       "    'dataset_image_key': 'image',\n",
       "    'dataset_image_label_key': 'label',\n",
       "    'n_shot': 0,\n",
       "    'masked_model': False,\n",
       "    'masked_token_str': '<mask>',\n",
       "    'masked_token_id': None,\n",
       "    'masked_frac_chosen': 0.15,\n",
       "    'masked_frac_chosen_masked': 0.8,\n",
       "    'masked_frac_chosen_randomized': 0.1,\n",
       "    'masked_frac_chosen_unchanged': 0.1,\n",
       "    'mmlu_subsets': None,\n",
       "    'generated_text_prompt': None,\n",
       "    'generated_text_include_prompt': False,\n",
       "    'generated_text_num_samples': 1,\n",
       "    'generated_text_length': 50,\n",
       "    'generated_text_temperature': None,\n",
       "    'mia_retain': None,\n",
       "    'mia_retain_split': None,\n",
       "    'mia_forget': None,\n",
       "    'mia_forget_split': None,\n",
       "    'mia_test': None,\n",
       "    'mia_test_split': None,\n",
       "    'misc': None}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from taker.eval import evaluate_all\n",
    "\n",
    "evaluate_all(m, 1e5, [\"pile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/taker/src/taker/model.py:1018: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  remove_indices = torch.tensor(remove_indices).to(self.device)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtaker\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprune\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prune_random\n\u001b[0;32m----> 3\u001b[0m ff_pruned, attn_pruned \u001b[38;5;241m=\u001b[39m prune_random(m, attn_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, ff_frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from taker.prune import prune_random\n",
    "\n",
    "ff_pruned, attn_pruned = prune_random(m, attn_frac=0.5, ff_frac=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 1., 0.,  ..., 0., 0., 1.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 1., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 1., 1.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 1., 0., 1.],\n",
      "         [0., 1., 0.,  ..., 1., 0., 1.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1., 1., 1.,  ..., 0., 0., 1.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 1.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 0., 1., 1.],\n",
      "         [0., 1., 0.,  ..., 0., 1., 1.]],\n",
      "\n",
      "        [[0., 1., 0.,  ..., 1., 1., 0.],\n",
      "         [0., 1., 0.,  ..., 1., 1., 0.]]], device='cuda:0',\n",
      "       grad_fn=<StackBackward0>)\n",
      "tensor([[[0., 0., 1.,  ..., 1., 1., 0.],\n",
      "         [0., 0., 1.,  ..., 1., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 1.,  ..., 0., 1., 0.],\n",
      "         [1., 0., 1.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 1., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 1., 0.]],\n",
      "\n",
      "        [[1., 0., 1.,  ..., 1., 0., 0.],\n",
      "         [1., 0., 1.,  ..., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 1.,  ..., 0., 0., 1.],\n",
      "         [1., 0., 1.,  ..., 0., 0., 1.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "vec = torch.ones([m.cfg.n_layers, 2, m.cfg.d_model]).to(m.device)\n",
    "print(m.run_masking(vec, \"attn_pre_out\"))\n",
    "print(m.run_inverse_masking(vec, \"attn_pre_out\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd3b3a066bc40428751c2bbb1f3f3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 67.55|37.63 (Skip: 58.61|31.05): : 100410it [05:32, 301.89it/s]                           \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_data': {'pile': {'perplexity': nan,\n",
       "   'loss': 3.5602,\n",
       "   'log_loss': 0.4922}},\n",
       " 'accuracy': {'pile': {'base': 37.632510133668795,\n",
       "   'topk': 67.55239713682477,\n",
       "   'skip': 31.046708495169803,\n",
       "   'topk_skip': 58.60770839557813}},\n",
       " 'misc': {'pile': {'accuracy_data': {'num_predictions': 135933,\n",
       "    'num_accurate': 51155,\n",
       "    'num_topk_accurate': 91826,\n",
       "    'num_skip_predictions': 100410,\n",
       "    'num_skip_accurate': 31174,\n",
       "    'num_topk_skip_accurate': 58848,\n",
       "    'token_counts': array([0., 0., 0., ..., 0., 0., 0.])},\n",
       "   'eval_config': {'dataset_name': 'pile',\n",
       "    'dataset_repo': 'monology/pile-uncopyrighted',\n",
       "    'dataset_subset': None,\n",
       "    'dataset_type': 'prediction',\n",
       "    'dataset_text_key': 'text',\n",
       "    'dataset_text_label_key': 'label',\n",
       "    'dataset_filter': None,\n",
       "    'dataset_has_test_split': True,\n",
       "    'dataset_split': None,\n",
       "    'streaming': True,\n",
       "    'sample_size': 100000.0,\n",
       "    'skip_token_strings': ['The',\n",
       "     'are',\n",
       "     'it',\n",
       "     '\\\\',\n",
       "     '*',\n",
       "     '-',\n",
       "     '  ',\n",
       "     'by',\n",
       "     '=',\n",
       "     ';',\n",
       "     'ing',\n",
       "     'was',\n",
       "     'as',\n",
       "     'be',\n",
       "     'on',\n",
       "     '/',\n",
       "     \"'\",\n",
       "     '(',\n",
       "     '               ',\n",
       "     'with',\n",
       "     '\\t',\n",
       "     '7',\n",
       "     'for',\n",
       "     'that',\n",
       "     ':',\n",
       "     '8',\n",
       "     ')',\n",
       "     '6',\n",
       "     's',\n",
       "     '9',\n",
       "     '(',\n",
       "     'is',\n",
       "     '5',\n",
       "     '4',\n",
       "     '_',\n",
       "     '3',\n",
       "     'in',\n",
       "     'a',\n",
       "     '-',\n",
       "     'to',\n",
       "     'and',\n",
       "     '2',\n",
       "     'of',\n",
       "     '1',\n",
       "     '0',\n",
       "     '',\n",
       "     'the',\n",
       "     ',',\n",
       "     '.',\n",
       "     '\\n'],\n",
       "    'skip_token_ids': [tensor(315, device='cuda:0'),\n",
       "     tensor(4871, device='cuda:0'),\n",
       "     tensor(44, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(947, device='cuda:0'),\n",
       "     tensor(45, device='cuda:0'),\n",
       "     tensor(85, device='cuda:0'),\n",
       "     tensor(862, device='cuda:0'),\n",
       "     tensor(637, device='cuda:0'),\n",
       "     tensor(304, device='cuda:0'),\n",
       "     tensor(2451, device='cuda:0'),\n",
       "     tensor(31, device='cuda:0'),\n",
       "     tensor(280, device='cuda:0'),\n",
       "     tensor(40, device='cuda:0'),\n",
       "     tensor(12369, device='cuda:0'),\n",
       "     tensor(1394, device='cuda:0'),\n",
       "     tensor(297, device='cuda:0'),\n",
       "     tensor(82, device='cuda:0'),\n",
       "     tensor(2182, device='cuda:0'),\n",
       "     tensor(51, device='cuda:0'),\n",
       "     tensor(49, device='cuda:0'),\n",
       "     tensor(2600, device='cuda:0'),\n",
       "     tensor(48, device='cuda:0'),\n",
       "     tensor(105, device='cuda:0'),\n",
       "     tensor(39, device='cuda:0'),\n",
       "     tensor(36, device='cuda:0'),\n",
       "     tensor(283, device='cuda:0'),\n",
       "     tensor(37, device='cuda:0'),\n",
       "     tensor(29, device='cuda:0'),\n",
       "     tensor(2388, device='cuda:0'),\n",
       "     tensor(43, device='cuda:0'),\n",
       "     tensor(480, device='cuda:0'),\n",
       "     tensor(831, device='cuda:0'),\n",
       "     tensor(305, device='cuda:0'),\n",
       "     tensor(317, device='cuda:0'),\n",
       "     tensor(220, device='cuda:0'),\n",
       "     tensor(42, device='cuda:0'),\n",
       "     tensor(87, device='cuda:0'),\n",
       "     tensor(221, device='cuda:0'),\n",
       "     tensor(592, device='cuda:0'),\n",
       "     tensor(32, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(46, device='cuda:0'),\n",
       "     tensor(47, device='cuda:0'),\n",
       "     tensor(41, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(38, device='cuda:0'),\n",
       "     tensor(34, device='cuda:0')],\n",
       "    'topk': 10,\n",
       "    'start_index': 0,\n",
       "    'num_texts_to_skip': 0,\n",
       "    'num_tokens_to_skip': 0,\n",
       "    'num_top_tokens': 50,\n",
       "    'loading_bar_desc': 'Acc',\n",
       "    'verbose': False,\n",
       "    'is_train_mode': False,\n",
       "    'dataset_image_key': 'image',\n",
       "    'dataset_image_label_key': 'label',\n",
       "    'n_shot': 0,\n",
       "    'masked_model': False,\n",
       "    'masked_token_str': '<mask>',\n",
       "    'masked_token_id': None,\n",
       "    'masked_frac_chosen': 0.15,\n",
       "    'masked_frac_chosen_masked': 0.8,\n",
       "    'masked_frac_chosen_randomized': 0.1,\n",
       "    'masked_frac_chosen_unchanged': 0.1,\n",
       "    'mmlu_subsets': None,\n",
       "    'generated_text_prompt': None,\n",
       "    'generated_text_include_prompt': False,\n",
       "    'generated_text_num_samples': 1,\n",
       "    'generated_text_length': 50,\n",
       "    'generated_text_temperature': None,\n",
       "    'mia_retain': None,\n",
       "    'mia_retain_split': None,\n",
       "    'mia_forget': None,\n",
       "    'mia_forget_split': None,\n",
       "    'mia_test': None,\n",
       "    'mia_test_split': None,\n",
       "    'misc': None}}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_all(m, 1e5, [\"pile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1000, 12, 64])\n"
     ]
    }
   ],
   "source": [
    "apo_rand_masked = m.run_inverse_masking(apo_rand, \"attn_pre_out\")\n",
    "print(apo_rand_masked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update_actadd(apo_rand_masked.reshape(12, 1000, m.cfg.d_model), \"attn_pre_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e3894f61226458098755509c85339e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Acc: 57.10|26.39 (Skip: 46.56|19.47): : 100410it [06:05, 274.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss_data': {'pile': {'perplexity': nan,\n",
       "   'loss': 4.4804,\n",
       "   'log_loss': 1.0563}},\n",
       " 'accuracy': {'pile': {'base': 26.386528657500385,\n",
       "   'topk': 57.09651078104655,\n",
       "   'skip': 19.465192709889454,\n",
       "   'topk_skip': 46.556119908375656}},\n",
       " 'misc': {'pile': {'accuracy_data': {'num_predictions': 135933,\n",
       "    'num_accurate': 35868,\n",
       "    'num_topk_accurate': 77613,\n",
       "    'num_skip_predictions': 100410,\n",
       "    'num_skip_accurate': 19545,\n",
       "    'num_topk_skip_accurate': 46747,\n",
       "    'token_counts': array([0., 0., 0., ..., 0., 0., 0.])},\n",
       "   'eval_config': {'dataset_name': 'pile',\n",
       "    'dataset_repo': 'monology/pile-uncopyrighted',\n",
       "    'dataset_subset': None,\n",
       "    'dataset_type': 'prediction',\n",
       "    'dataset_text_key': 'text',\n",
       "    'dataset_text_label_key': 'label',\n",
       "    'dataset_filter': None,\n",
       "    'dataset_has_test_split': True,\n",
       "    'dataset_split': None,\n",
       "    'streaming': True,\n",
       "    'sample_size': 100000.0,\n",
       "    'skip_token_strings': ['The',\n",
       "     'are',\n",
       "     'it',\n",
       "     '\\\\',\n",
       "     '*',\n",
       "     '-',\n",
       "     '  ',\n",
       "     'by',\n",
       "     '=',\n",
       "     ';',\n",
       "     'ing',\n",
       "     'was',\n",
       "     'as',\n",
       "     'be',\n",
       "     'on',\n",
       "     '/',\n",
       "     \"'\",\n",
       "     '(',\n",
       "     '               ',\n",
       "     'with',\n",
       "     '\\t',\n",
       "     '7',\n",
       "     'for',\n",
       "     'that',\n",
       "     ':',\n",
       "     '8',\n",
       "     ')',\n",
       "     '6',\n",
       "     's',\n",
       "     '9',\n",
       "     '(',\n",
       "     'is',\n",
       "     '5',\n",
       "     '4',\n",
       "     '_',\n",
       "     '3',\n",
       "     'in',\n",
       "     'a',\n",
       "     '-',\n",
       "     'to',\n",
       "     'and',\n",
       "     '2',\n",
       "     'of',\n",
       "     '1',\n",
       "     '0',\n",
       "     '',\n",
       "     'the',\n",
       "     ',',\n",
       "     '.',\n",
       "     '\\n'],\n",
       "    'skip_token_ids': [tensor(637, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(2600, device='cuda:0'),\n",
       "     tensor(2388, device='cuda:0'),\n",
       "     tensor(220, device='cuda:0'),\n",
       "     tensor(280, device='cuda:0'),\n",
       "     tensor(592, device='cuda:0'),\n",
       "     tensor(32, device='cuda:0'),\n",
       "     tensor(82, device='cuda:0'),\n",
       "     tensor(283, device='cuda:0'),\n",
       "     tensor(45, device='cuda:0'),\n",
       "     tensor(4871, device='cuda:0'),\n",
       "     tensor(48, device='cuda:0'),\n",
       "     tensor(44, device='cuda:0'),\n",
       "     tensor(87, device='cuda:0'),\n",
       "     tensor(34, device='cuda:0'),\n",
       "     tensor(2182, device='cuda:0'),\n",
       "     tensor(51, device='cuda:0'),\n",
       "     tensor(47, device='cuda:0'),\n",
       "     tensor(35, device='cuda:0'),\n",
       "     tensor(49, device='cuda:0'),\n",
       "     tensor(1394, device='cuda:0'),\n",
       "     tensor(43, device='cuda:0'),\n",
       "     tensor(41, device='cuda:0'),\n",
       "     tensor(862, device='cuda:0'),\n",
       "     tensor(947, device='cuda:0'),\n",
       "     tensor(39, device='cuda:0'),\n",
       "     tensor(304, device='cuda:0'),\n",
       "     tensor(2451, device='cuda:0'),\n",
       "     tensor(297, device='cuda:0'),\n",
       "     tensor(221, device='cuda:0'),\n",
       "     tensor(12369, device='cuda:0'),\n",
       "     tensor(37, device='cuda:0'),\n",
       "     tensor(29, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(46, device='cuda:0'),\n",
       "     tensor(31, device='cuda:0'),\n",
       "     tensor(30, device='cuda:0'),\n",
       "     tensor(305, device='cuda:0'),\n",
       "     tensor(105, device='cuda:0'),\n",
       "     tensor(42, device='cuda:0'),\n",
       "     tensor(480, device='cuda:0'),\n",
       "     tensor(38, device='cuda:0'),\n",
       "     tensor(831, device='cuda:0'),\n",
       "     tensor(36, device='cuda:0'),\n",
       "     tensor(315, device='cuda:0'),\n",
       "     tensor(317, device='cuda:0'),\n",
       "     tensor(85, device='cuda:0'),\n",
       "     tensor(40, device='cuda:0')],\n",
       "    'topk': 10,\n",
       "    'start_index': 0,\n",
       "    'num_texts_to_skip': 0,\n",
       "    'num_tokens_to_skip': 0,\n",
       "    'num_top_tokens': 50,\n",
       "    'loading_bar_desc': 'Acc',\n",
       "    'verbose': False,\n",
       "    'is_train_mode': False,\n",
       "    'dataset_image_key': 'image',\n",
       "    'dataset_image_label_key': 'label',\n",
       "    'n_shot': 0,\n",
       "    'masked_model': False,\n",
       "    'masked_token_str': '<mask>',\n",
       "    'masked_token_id': None,\n",
       "    'masked_frac_chosen': 0.15,\n",
       "    'masked_frac_chosen_masked': 0.8,\n",
       "    'masked_frac_chosen_randomized': 0.1,\n",
       "    'masked_frac_chosen_unchanged': 0.1,\n",
       "    'mmlu_subsets': None,\n",
       "    'generated_text_prompt': None,\n",
       "    'generated_text_include_prompt': False,\n",
       "    'generated_text_num_samples': 1,\n",
       "    'generated_text_length': 50,\n",
       "    'generated_text_temperature': None,\n",
       "    'mia_retain': None,\n",
       "    'mia_retain_split': None,\n",
       "    'mia_forget': None,\n",
       "    'mia_forget_split': None,\n",
       "    'mia_test': None,\n",
       "    'mia_test_split': None,\n",
       "    'misc': None}}}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_all(m, 1e5, [\"pile\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
