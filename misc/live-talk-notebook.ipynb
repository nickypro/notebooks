{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cf62433bae4322a026b2664b3e5c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'google/gemma-2b-it' with int4:\n",
      "- Added 288 hooks across 18 layers\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from taker import Model\n",
    "\n",
    "m = Model(\"google/gemma-2b-it\", dtype=\"int4\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Hello world in python:',\n",
       " '\\n\\n```python\\nprint(\"Hello world\")\\n```\\n\\n**Output:**\\n\\n```\\nHello world\\n```\\n\\n**Explanation:**\\n\\n1. `print()` is a built-in Python function that prints the given argument to the console.\\n2. `\"Hello world\"` is the argument that we are passing to `print()`.\\n3. The `print()` function will call the `__str__()` method of the string `\"Hello world\"` and print the output.\\n\\n**')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.generate(\"Hello world in python:\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 37, 4, 2048])\n",
      "torch.Size([1, 19, 4, 2048])\n",
      "torch.Size([1, 18, 4, 16384]) torch.Size([1, 18, 4, 8, 256])\n"
     ]
    }
   ],
   "source": [
    "res = m.get_residual_stream(\"Hello world!\")\n",
    "print(res.shape)\n",
    "\n",
    "res = m.get_residual_stream_decoder(\"Hello world!\")\n",
    "print(res.shape)\n",
    "\n",
    "act = m.get_midlayer_activations(\"Hello world!\")\n",
    "print(act[\"mlp\"].shape, act[\"attn\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, tensor([[[[ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01],\n",
      "          [ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01],\n",
      "          [ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01],\n",
      "          ...,\n",
      "          [ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01],\n",
      "          [ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01],\n",
      "          [ 9.4727e-02, -1.3330e-01, -6.3354e-02,  ...,  1.0071e-01,\n",
      "            9.3506e-02, -1.0907e-01]],\n",
      "\n",
      "         [[ 7.1838e-02, -1.4087e-01, -8.5022e-02,  ...,  9.3323e-02,\n",
      "            9.8633e-02, -1.0114e-01],\n",
      "          [-3.5864e-01, -2.8320e-01, -4.9292e-01,  ..., -4.5044e-02,\n",
      "            1.9543e-01,  4.8096e-02],\n",
      "          [-1.2002e+00, -5.6152e-01, -1.2900e+00,  ..., -3.1543e-01,\n",
      "            3.8452e-01,  3.3984e-01],\n",
      "          ...,\n",
      "          [ 6.2103e-02, -1.4404e-01, -9.4238e-02,  ...,  9.0210e-02,\n",
      "            1.0083e-01, -9.7778e-02],\n",
      "          [-7.1143e-01, -3.9990e-01, -8.2715e-01,  ..., -1.5857e-01,\n",
      "            2.7490e-01,  1.7053e-01],\n",
      "          [-4.9316e-02, -1.8091e-01, -1.9983e-01,  ...,  5.4413e-02,\n",
      "            1.2585e-01, -5.9143e-02]],\n",
      "\n",
      "         [[ 8.7646e-02, -1.3782e-01, -6.8359e-02,  ...,  9.7412e-02,\n",
      "            9.5154e-02, -1.0614e-01],\n",
      "          [-2.4121e-01, -2.9761e-01, -3.4009e-01,  ..., -3.2227e-02,\n",
      "            1.7053e-01,  1.8997e-02],\n",
      "          [-1.1201e+00, -1.9736e+00, -9.5520e-02,  ..., -9.6436e-01,\n",
      "            4.0723e-01,  6.2646e-01],\n",
      "          ...,\n",
      "          [ 4.7272e-02, -1.6382e-01, -9.6802e-02,  ...,  7.8491e-02,\n",
      "            1.0461e-01, -8.9417e-02],\n",
      "          [-7.8613e-01, -1.2090e+00, -2.8784e-01,  ..., -5.5029e-01,\n",
      "            3.1372e-01,  3.6743e-01],\n",
      "          [-2.1378e-02, -1.9885e-01, -1.5222e-01,  ...,  5.0629e-02,\n",
      "            1.2036e-01, -6.2866e-02]],\n",
      "\n",
      "         [[ 8.5876e-02, -1.3623e-01, -6.9702e-02,  ...,  9.7107e-02,\n",
      "            9.5215e-02, -1.0614e-01],\n",
      "          [-4.5349e-02, -1.4612e-01, -8.7158e-02,  ...,  2.2156e-02,\n",
      "            1.0474e-01, -7.6721e-02],\n",
      "          [-9.9658e-01,  4.4092e-01,  5.7129e-01,  ..., -6.8555e-01,\n",
      "           -3.0869e-02, -9.2651e-02],\n",
      "          ...,\n",
      "          [ 6.7871e-02, -1.4844e-01, -8.1787e-02,  ...,  8.8379e-02,\n",
      "            9.9426e-02, -9.8511e-02],\n",
      "          [-1.6117e-03, -1.2988e-01, -5.7373e-02,  ...,  4.0802e-02,\n",
      "            9.6313e-02, -9.1614e-02],\n",
      "          [-2.4512e-01, -3.1958e-01, -2.5684e-01,  ..., -6.9153e-02,\n",
      "            1.6187e-01,  2.0233e-02]],\n",
      "\n",
      "         [[ 8.8623e-02, -1.3574e-01, -6.5002e-02,  ...,  9.8755e-02,\n",
      "            9.3994e-02, -1.0895e-01],\n",
      "          [-3.0029e-01,  8.3679e-02,  1.9153e-01,  ..., -1.6895e-01,\n",
      "            3.8544e-02, -1.3342e-01],\n",
      "          [-5.0049e-01, -1.0815e-01,  8.0273e-01,  ...,  5.9912e-01,\n",
      "           -2.7222e-01, -1.4189e+00],\n",
      "          ...,\n",
      "          [ 5.7098e-02, -1.4917e-01, -8.2092e-02,  ...,  8.4656e-02,\n",
      "            9.9365e-02, -9.9548e-02],\n",
      "          [-1.0168e-01, -2.0044e-01, -1.6345e-01,  ...,  5.3040e-02,\n",
      "            1.1499e-01, -1.0101e-01],\n",
      "          [-6.5527e-01,  3.6438e-02,  1.9470e-01,  ..., -4.0112e-01,\n",
      "            6.1493e-02, -4.3304e-02]],\n",
      "\n",
      "         [[ 5.6366e-02, -1.4258e-01, -6.7017e-02,  ...,  1.0748e-01,\n",
      "            8.2581e-02, -1.2769e-01],\n",
      "          [-3.4717e-01, -6.3843e-02,  5.4102e-01,  ...,  5.1025e-01,\n",
      "           -2.2046e-01, -1.0791e+00],\n",
      "          [-1.3359e+00,  5.8008e-01, -6.0107e-01,  ...,  2.5742e+00,\n",
      "           -1.8975e+00, -2.3320e+00],\n",
      "          ...,\n",
      "          [ 2.3849e-02, -1.2561e-01, -1.3695e-02,  ...,  1.4807e-01,\n",
      "            5.1819e-02, -2.1436e-01],\n",
      "          [-5.1123e-01, -3.1812e-01, -5.4541e-01,  ...,  3.9856e-02,\n",
      "            1.0388e-01, -3.7872e-02],\n",
      "          [-4.6924e-01, -2.2339e-02,  5.7031e-01,  ...,  3.1641e-01,\n",
      "           -1.7749e-01, -9.5068e-01]]]], device='cuda:0', dtype=torch.float16), None, None, tensor([[[[-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01],\n",
      "          [-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01],\n",
      "          [-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01],\n",
      "          ...,\n",
      "          [-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01],\n",
      "          [-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01],\n",
      "          [-2.7142e-03,  1.1514e+00,  7.0007e-02,  ...,  4.8218e-03,\n",
      "           -6.0791e-02, -1.8506e-01]],\n",
      "\n",
      "         [[-1.7102e-01,  1.1611e+00,  1.6626e-01,  ..., -7.3059e-02,\n",
      "           -2.7026e-01, -2.0789e-01],\n",
      "          [-4.0741e-03,  1.1514e+00,  7.0801e-02,  ...,  4.1924e-03,\n",
      "           -6.2500e-02, -1.8530e-01],\n",
      "          [-4.4586e-02,  1.1543e+00,  9.3933e-02,  ..., -1.4549e-02,\n",
      "           -1.1292e-01, -1.9080e-01],\n",
      "          ...,\n",
      "          [-7.0305e-03,  1.1514e+00,  7.2449e-02,  ...,  2.8248e-03,\n",
      "           -6.6162e-02, -1.8567e-01],\n",
      "          [-1.0132e-02,  1.1514e+00,  7.4280e-02,  ...,  1.3895e-03,\n",
      "           -7.0007e-02, -1.8604e-01],\n",
      "          [-3.9642e-02,  1.1533e+00,  9.1125e-02,  ..., -1.2260e-02,\n",
      "           -1.0675e-01, -1.9006e-01]],\n",
      "\n",
      "         [[-3.4497e-01,  8.3057e-01,  2.2839e-01,  ..., -2.7661e-01,\n",
      "           -7.0215e-01, -6.8506e-01],\n",
      "          [-5.4398e-03,  1.1494e+00,  7.1411e-02,  ...,  2.9602e-03,\n",
      "           -6.5247e-02, -1.8762e-01],\n",
      "          [-1.0236e-01,  1.1426e+00,  1.2537e-01,  ..., -4.6722e-02,\n",
      "           -1.9434e-01, -2.1863e-01],\n",
      "          ...,\n",
      "          [-2.9099e-02,  1.1270e+00,  8.2275e-02,  ..., -1.6708e-02,\n",
      "           -1.0992e-01, -2.2302e-01],\n",
      "          [-1.6342e-02,  1.1416e+00,  7.6660e-02,  ..., -5.3177e-03,\n",
      "           -8.4473e-02, -2.0105e-01],\n",
      "          [-4.9866e-02,  1.1387e+00,  9.5215e-02,  ..., -2.2751e-02,\n",
      "           -1.2952e-01, -2.1265e-01]],\n",
      "\n",
      "         [[ 1.1060e-01,  8.4473e-01, -3.5352e-01,  ...,  3.2715e-02,\n",
      "           -2.6562e-01, -2.9565e-01],\n",
      "          [-3.3550e-03,  1.1465e+00,  6.5735e-02,  ...,  3.8071e-03,\n",
      "           -6.6650e-02, -1.8823e-01],\n",
      "          [-9.8145e-02,  1.1289e+00,  1.1389e-01,  ..., -4.7424e-02,\n",
      "           -2.0081e-01, -2.2876e-01],\n",
      "          ...,\n",
      "          [-2.4986e-03,  1.1484e+00,  6.6772e-02,  ...,  4.5128e-03,\n",
      "           -6.3843e-02, -1.8689e-01],\n",
      "          [ 2.1114e-03,  1.1387e+00,  5.1880e-02,  ...,  6.0692e-03,\n",
      "           -6.9458e-02, -1.8958e-01],\n",
      "          [-2.1515e-02,  1.1201e+00,  5.4718e-02,  ..., -9.9792e-03,\n",
      "           -1.1572e-01, -2.1252e-01]],\n",
      "\n",
      "         [[ 1.4099e-01,  6.9727e-01,  4.4250e-02,  ..., -1.0078e-02,\n",
      "           -4.3750e-01, -7.2266e-01],\n",
      "          [ 5.9986e-04,  1.1230e+00,  6.7871e-02,  ...,  8.2684e-04,\n",
      "           -9.0149e-02, -2.1863e-01],\n",
      "          [-1.7114e-01,  1.0850e+00,  1.4673e-01,  ..., -9.4482e-02,\n",
      "           -3.3569e-01, -2.9712e-01],\n",
      "          ...,\n",
      "          [-2.9545e-03,  1.1475e+00,  6.9885e-02,  ...,  4.0741e-03,\n",
      "           -6.5308e-02, -1.8909e-01],\n",
      "          [ 5.8746e-03,  1.1240e+00,  6.8787e-02,  ...,  3.8738e-03,\n",
      "           -8.3557e-02, -2.1765e-01],\n",
      "          [-8.6746e-03,  1.1191e+00,  6.2317e-02,  ..., -4.1122e-03,\n",
      "           -1.0394e-01, -2.1887e-01]],\n",
      "\n",
      "         [[-7.5989e-02, -3.0664e-01, -1.5723e-01,  ...,  6.5674e-02,\n",
      "           -3.4961e-01, -4.6655e-01],\n",
      "          [-4.7379e-03,  1.1348e+00,  6.7749e-02,  ...,  4.2686e-03,\n",
      "           -6.8298e-02, -1.9080e-01],\n",
      "          [-9.3384e-02,  9.7510e-01,  9.0698e-02,  ..., -5.6610e-02,\n",
      "           -2.8418e-01, -3.3081e-01],\n",
      "          ...,\n",
      "          [-1.4038e-02,  1.0986e+00,  6.5796e-02,  ...,  2.3422e-03,\n",
      "           -8.4167e-02, -1.9849e-01],\n",
      "          [-6.2714e-03,  1.1230e+00,  6.6711e-02,  ...,  4.9324e-03,\n",
      "           -6.9153e-02, -1.9104e-01],\n",
      "          [ 5.1575e-03,  1.0859e+00,  5.7953e-02,  ...,  2.5387e-03,\n",
      "           -1.0370e-01, -2.3547e-01]]]], device='cuda:0', dtype=torch.float16), None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[None, None, tensor([[[ 3.4922,  0.0370, -0.9604,  ...,  0.5151,  0.0405,  0.2961],\n",
      "         [ 0.1306, -0.8940,  0.1858,  ..., -0.8291, -0.0439, -0.7671],\n",
      "         [-0.2280, -0.2499, -0.3384,  ..., -0.1930, -0.1356, -0.9209],\n",
      "         [-0.3088, -1.1895, -0.4280,  ..., -0.3250, -0.2786,  0.5376],\n",
      "         [-0.2939,  0.0984, -0.1548,  ...,  0.0302,  0.7803,  0.9692],\n",
      "         [-0.6709, -0.4966,  0.2217,  ...,  1.3896,  0.7148, -0.7002]]],\n",
      "       device='cuda:0', dtype=torch.float16), None, None, tensor([[[ 3.4824, -0.1544, -1.0098,  ...,  0.5410, -0.1958,  0.4163],\n",
      "         [ 0.0228, -0.2286,  0.1051,  ...,  0.0284,  0.0400, -0.0707],\n",
      "         [-0.0120, -0.0522, -0.1448,  ..., -0.0931,  0.0400, -0.2856],\n",
      "         [ 0.0839, -0.4551, -0.1555,  ..., -0.0959,  0.0348, -0.1863],\n",
      "         [ 0.0055,  0.1825, -0.1036,  ...,  0.2466,  0.0844,  0.3308],\n",
      "         [ 0.2542, -0.5664, -0.3154,  ...,  0.6606,  0.2637, -0.1498]]],\n",
      "       device='cuda:0', dtype=torch.float16), None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "m.hooks.disable_all_collect_hooks()\n",
    "\n",
    "m.hooks.enable_collect_hooks([\"attn_pre_out\", \"pre_decoder\"], layers=[2,5])\n",
    "\n",
    "m.get_outputs_embeds(\"This is some example text\")\n",
    "\n",
    "print( m.hooks[\"attn_pre_out\"][\"collect\"] )\n",
    "print( m.hooks[\"pre_decoder\"][\"collect\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n",
      "[None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "print( m.hooks[\"attn_pre_out\"][\"collect\"] )\n",
    "print( m.hooks[\"pre_decoder\"][\"collect\"] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0352e-01,  5.0354e-03, -3.2715e-02,  ..., -1.7334e-02,\n",
      "           -8.9111e-03, -1.0254e-02],\n",
      "          [ 3.0859e-01, -5.3223e-02,  1.6357e-02,  ...,  3.4180e-03,\n",
      "            1.0010e-01, -2.4292e-02],\n",
      "          [ 2.3340e-01, -9.7656e-02, -2.8687e-03,  ..., -3.3936e-02,\n",
      "            6.4941e-02, -1.4258e-01],\n",
      "          [ 1.9922e-01,  4.2236e-02, -1.4453e-01,  ...,  9.3384e-03,\n",
      "            1.9531e-02, -2.8931e-02]],\n",
      "\n",
      "         [[ 3.7383e+00,  4.4922e-02, -1.0879e+00,  ...,  3.7109e-01,\n",
      "            2.3010e-02,  1.7102e-01],\n",
      "          [ 3.9023e+00, -2.1836e+00,  1.1094e+00,  ...,  1.1309e+00,\n",
      "            8.0078e-01, -4.5044e-01],\n",
      "          [ 1.0137e+00, -1.2432e+00,  1.7749e-01,  ..., -1.2676e+00,\n",
      "            3.9062e-02, -2.8203e+00],\n",
      "          [ 1.5830e+00,  9.1016e-01, -1.8301e+00,  ...,  2.9297e-03,\n",
      "           -1.0089e-01, -9.0137e-01]],\n",
      "\n",
      "         [[ 3.4922e+00,  3.7048e-02, -9.6045e-01,  ...,  5.1514e-01,\n",
      "            4.0466e-02,  2.9614e-01],\n",
      "          [ 5.8594e-01, -1.0215e+00,  2.4219e-01,  ...,  1.1406e+00,\n",
      "            5.6006e-01, -3.5986e-01],\n",
      "          [-1.3025e-01,  1.4648e-03,  1.7627e-01,  ..., -8.7744e-01,\n",
      "            3.3203e-01, -1.4277e+00],\n",
      "          [-4.0625e-01,  3.2812e-01, -5.8594e-01,  ...,  3.5278e-01,\n",
      "            8.0566e-02, -7.8027e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.1211e+00, -2.9614e-01, -1.4111e+00,  ...,  1.2659e-01,\n",
      "           -7.9980e-01, -3.2178e-01],\n",
      "          [-4.2871e-01, -1.1152e+00, -6.3086e-01,  ..., -6.4600e-01,\n",
      "           -5.3223e-01, -1.0176e+00],\n",
      "          [-2.1814e-01,  3.0127e-01, -2.5024e-01,  ..., -1.4722e-01,\n",
      "            1.1121e-01, -1.1953e+00],\n",
      "          [-3.8818e-01, -3.9087e-01, -3.0933e-01,  ...,  8.0176e-01,\n",
      "           -1.5410e+00, -1.6895e+00]],\n",
      "\n",
      "         [[-3.7109e-01, -1.8860e-01, -1.4844e+00,  ..., -9.4238e-01,\n",
      "           -1.4512e+00, -2.0957e+00],\n",
      "          [-5.7227e-01, -9.4434e-01, -9.5947e-01,  ..., -5.2832e-01,\n",
      "           -2.6929e-01, -1.1738e+00],\n",
      "          [-3.5010e-01,  1.8384e-01, -5.4053e-01,  ..., -1.8311e-01,\n",
      "            2.0215e-01, -1.1260e+00],\n",
      "          [-2.5024e-01, -5.4395e-01, -8.4375e-01,  ...,  1.2881e+00,\n",
      "           -1.1191e+00, -1.8320e+00]],\n",
      "\n",
      "         [[ 5.0312e+00, -8.4453e+00, -2.9531e+00,  ..., -4.6328e+00,\n",
      "           -5.9766e+00, -4.3906e+00],\n",
      "          [-9.6387e-01, -9.8096e-01, -1.1025e+00,  ..., -5.7031e-01,\n",
      "           -1.6760e-01, -8.3740e-01],\n",
      "          [-7.1777e-01,  3.2007e-01, -7.3877e-01,  ..., -4.7388e-01,\n",
      "            4.3555e-01, -8.9062e-01],\n",
      "          [-6.3037e-01, -6.2012e-01, -1.0146e+00,  ...,  1.2188e+00,\n",
      "           -8.2324e-01, -1.5078e+00]]]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# We get the residual stream with no changes\n",
    "m.hooks.neuron_replace[\"layer_0_mlp_pre_out\"].reset()\n",
    "res1 = m.get_residual_stream(\"Some text here\")[:,:4,:3,:5]\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 4, already saw 0, checking 2 out of max 2\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 2.0508,  0.0182,  6.1211, -2.1406, -0.3552],\n",
      "          [ 0.0000, -0.0000, -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 2.7734, -0.0179, -0.0384, -1.0674,  1.4033],\n",
      "          [-1.6133, -0.0564, -0.1362, -0.1129, -0.1021]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# We get the residual stream when we change:\n",
    "# - layer 0 MLP, token 1, to all zeros\n",
    "m.hooks.neuron_replace[\"layer_0_mlp_pre_out\"].add_token(\n",
    "    1, torch.zeros([m.cfg.d_mlp])\n",
    ")\n",
    "res2 = m.get_residual_stream(\"Some text here\")[:,:4,:3,:5]\n",
    "print((res2-res1)/res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "tensor([[[[ 4.6836e+00,  2.2791e-01, -1.4805e+00,  6.5247e-02, -7.5098e-01],\n",
      "          [ 8.3516e+00, -2.8281e+00, -8.0859e+00,  1.6465e+00, -1.2539e+00]],\n",
      "\n",
      "         [[ 3.5859e+00,  2.3853e-01, -7.8125e-01,  7.0801e-03, -2.4658e-01],\n",
      "          [ 4.5234e+00, -1.7100e+00, -4.1680e+00,  1.5674e+00, -8.9844e-02]],\n",
      "\n",
      "         [[ 3.7383e+00,  4.4922e-02, -1.0879e+00,  2.9956e-01, -1.2048e-01],\n",
      "          [ 4.5234e+00, -1.7100e+00, -4.1680e+00,  1.5674e+00, -8.9844e-02]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<SliceBackward0>)\n",
      "OrderedDict([('param', tensor([0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
      "       dtype=torch.float16))])\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0008, -0.0000],\n",
      "          [-0.0026, -0.0034,  0.0056, -0.0100, -0.0007]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "tensor([[[[ 1.6562e+00,  2.6978e-01,  7.5806e-02, -3.0859e-01, -1.4281e+01],\n",
      "          [        nan,         nan,         nan,         nan,         nan]],\n",
      "\n",
      "         [[-0.0000e+00,  7.8440e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-6.1989e-03, -1.9028e-02,  3.2043e-02, -3.9429e-02,  5.3072e-04]],\n",
      "\n",
      "         [[-0.0000e+00, -0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-2.2850e-03,  1.0010e-02,  5.2299e-03,  8.1329e-03, -8.2214e-02]],\n",
      "\n",
      "         [[-0.0000e+00,  0.0000e+00, -0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
      "          [ 1.5152e-02, -7.2765e-04, -3.4046e-03,  0.0000e+00,  3.5419e-03]],\n",
      "\n",
      "         [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00,  6.3658e-04],\n",
      "          [-9.2087e-03,  4.0474e-03, -1.6108e-03,  1.1017e-02,  8.3618e-03]],\n",
      "\n",
      "         [[ 0.0000e+00, -7.8249e-04,  0.0000e+00,  0.0000e+00, -6.1512e-04],\n",
      "          [ 1.0300e-03, -3.6743e-02,  3.0411e-02, -6.3934e-03, -5.9843e-04]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -7.9012e-04, -0.0000e+00, -0.0000e+00],\n",
      "          [-3.1242e-03,  3.3531e-03,  5.6229e-03, -2.8961e-02, -3.0624e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  5.3596e-04,  0.0000e+00, -1.1139e-03],\n",
      "          [ 1.0754e-01, -1.1971e-02, -3.3855e-03, -2.7328e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-8.6451e-04, -5.2643e-04, -0.0000e+00, -0.0000e+00, -8.3065e-04],\n",
      "          [ 1.7349e-02, -1.2512e-02, -1.6155e-03, -1.4429e-03, -6.6162e-02]],\n",
      "\n",
      "         [[ 5.2357e-04, -7.8058e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-2.0065e-02,  1.0252e-03,  7.2083e-02, -6.6833e-03,  6.2646e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  1.3151e-03, -0.0000e+00, -0.0000e+00],\n",
      "          [ 3.8052e-03, -6.8665e-03, -1.5976e-02, -4.2496e-03, -7.6233e-02]],\n",
      "\n",
      "         [[ 7.7343e-04, -0.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [ 1.4374e-02,  6.9809e-03, -4.3564e-03,  3.0956e-03, -3.7689e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00,  9.2506e-04, -0.0000e+00,  0.0000e+00],\n",
      "          [ 9.1248e-03, -1.4389e-02, -7.4530e-04, -6.2744e-02, -1.4832e-01]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -8.3542e-04, -0.0000e+00,  1.0309e-03],\n",
      "          [ 7.9250e-04,  4.6616e-03,  1.6907e-02, -1.0864e-02,  5.4550e-03]],\n",
      "\n",
      "         [[-8.8167e-04,  0.0000e+00, -0.0000e+00,  2.7142e-03, -0.0000e+00],\n",
      "          [ 1.0338e-02, -1.9165e-02, -2.6840e-02, -5.2595e-04, -1.8263e-03]],\n",
      "\n",
      "         [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00,  1.8568e-03],\n",
      "          [ 1.3275e-02, -2.2926e-03,  1.1147e-02, -3.2013e-02,  8.1635e-04]],\n",
      "\n",
      "         [[-0.0000e+00, -6.7377e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-1.2970e-02, -9.5444e-03,  8.2245e-03,  1.1182e-01, -1.7700e-02]],\n",
      "\n",
      "         [[-6.4898e-04, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
      "          [-2.4078e-02,  1.4553e-03,  3.1204e-02, -9.1629e-03,  6.9141e-04]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "offset_layer_0 = m.hooks.neuron_offsets[\"layer_0_mlp_pre_out\"]\n",
    "offset_layer_0.param.data = torch.zeros_like(offset_layer_0.param.data)\n",
    "res1 = m.get_residual_stream(\".\")[..., :3, :, :5]\n",
    "mlp1 = m.get_midlayer_activations(\".\")[\"mlp\"][..., :5]\n",
    "print(res1)\n",
    "\n",
    "offset_layer_0.param.data = torch.ones_like(offset_layer_0.param.data) * 0.01\n",
    "print(offset_layer_0.state_dict())\n",
    "res2 = m.get_residual_stream(\".\")[..., :3, :, :5]\n",
    "mlp2 = m.get_midlayer_activations(\".\")[\"mlp\"][..., :5]\n",
    "\n",
    "print((res1-res2)/res1)\n",
    "print((mlp1-mlp2)/mlp1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "tensor([[[[ 4.6836e+00,  2.2791e-01, -1.4805e+00,  6.5247e-02, -7.5098e-01],\n",
      "          [ 8.3516e+00, -2.8281e+00, -8.0859e+00,  1.6465e+00, -1.2539e+00]],\n",
      "\n",
      "         [[ 3.5859e+00,  2.3853e-01, -7.8125e-01,  7.0801e-03, -2.4658e-01],\n",
      "          [ 4.5234e+00, -1.7100e+00, -4.1680e+00,  1.5674e+00, -8.9844e-02]],\n",
      "\n",
      "         [[ 3.7383e+00,  4.4922e-02, -1.0879e+00,  2.9932e-01, -1.2048e-01],\n",
      "          [ 4.5352e+00, -1.7158e+00, -4.1445e+00,  1.5830e+00, -8.9905e-02]]]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<SliceBackward0>)\n",
      "OrderedDict([('param', tensor([0.0100, 0.0100, 0.0100,  ..., 0.0100, 0.0100, 0.0100], device='cuda:0',\n",
      "       dtype=torch.float16))])\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "Got 2, already saw 0, checking 2 out of max 2\n",
      "tensor([[[[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000, -0.0027, -0.0000, -0.0008, -0.0030],\n",
      "          [ 0.0000, -0.0000, -0.0000,  0.0000, -0.0000]]]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<DivBackward0>)\n",
      "tensor([[[[ 0.0000e+00,  1.0000e+00, -0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [        nan,         nan,         nan,         nan,         nan]],\n",
      "\n",
      "         [[-1.8997e-03, -7.8487e-04, -0.0000e+00, -9.7847e-04, -0.0000e+00],\n",
      "          [-0.0000e+00,  0.0000e+00,  8.4877e-04, -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  9.3269e-04,  1.3847e-03],\n",
      "          [ 1.5202e-03,  2.0218e-03,  5.2595e-04,  0.0000e+00, -5.8022e-03]],\n",
      "\n",
      "         [[-0.0000e+00, -9.3126e-04, -6.3515e-04, -0.0000e+00, -8.5926e-04],\n",
      "          [-2.5635e-03, -0.0000e+00,  0.0000e+00, -9.4795e-04,  5.0774e-03]],\n",
      "\n",
      "         [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  9.5034e-04, -7.0076e-03],\n",
      "          [ 0.0000e+00,  6.7759e-04, -4.8218e-03, -7.9536e-04, -4.6844e-03]],\n",
      "\n",
      "         [[-5.9748e-04,  2.3460e-03, -1.6909e-03,  0.0000e+00,  6.1464e-04],\n",
      "          [ 1.0319e-03,  3.8818e-02, -2.7866e-03,  1.0586e-03,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.1301e-03,  0.0000e+00, -1.5783e-03, -1.3285e-03, -0.0000e+00],\n",
      "          [ 1.2465e-03,  1.6823e-03,  0.0000e+00,  8.0414e-03,  0.0000e+00]],\n",
      "\n",
      "         [[ 0.0000e+00,  4.9686e-04, -5.3644e-04, -5.6505e-04,  6.6757e-03],\n",
      "          [ 1.4944e-03,  7.3910e-04,  3.9368e-03,  3.7994e-03, -1.1921e-03]],\n",
      "\n",
      "         [[ 0.0000e+00,  5.2595e-04, -0.0000e+00, -0.0000e+00,  8.2970e-04],\n",
      "          [-4.0741e-03,  1.8539e-03,  2.9037e-02, -2.1610e-03,  2.3270e-02]],\n",
      "\n",
      "         [[-5.2404e-04,  0.0000e+00, -0.0000e+00, -0.0000e+00,  1.7920e-03],\n",
      "          [ 5.7106e-03, -1.0271e-03, -6.0701e-04,  2.4147e-03,  7.6233e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  8.8644e-04, -1.9741e-03,  8.5640e-04, -0.0000e+00],\n",
      "          [-9.5510e-04,  5.6801e-03, -2.6207e-03,  1.8139e-03, -3.0346e-03]],\n",
      "\n",
      "         [[ 7.7391e-04, -0.0000e+00, -0.0000e+00, -1.0757e-03,  0.0000e+00],\n",
      "          [-3.6469e-03,  1.5059e-03, -0.0000e+00, -1.5526e-03,  2.3941e-02]],\n",
      "\n",
      "         [[ 0.0000e+00,  0.0000e+00, -9.2602e-04, -0.0000e+00,  0.0000e+00],\n",
      "          [-3.9482e-03,  1.3298e-02, -7.4482e-04, -2.9236e-02,  4.2786e-02]],\n",
      "\n",
      "         [[-5.6076e-04,  0.0000e+00,  8.3494e-04, -0.0000e+00,  0.0000e+00],\n",
      "          [ 7.9298e-04,  9.3651e-04, -5.0163e-03, -8.2636e-04, -1.5678e-03]],\n",
      "\n",
      "         [[ 8.8120e-04,  0.0000e+00, -0.0000e+00, -2.1782e-03, -0.0000e+00],\n",
      "          [ 1.7414e-03,  5.1270e-03, -9.4528e-03, -1.5764e-03,  0.0000e+00]],\n",
      "\n",
      "         [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00, -1.8606e-03],\n",
      "          [-1.6823e-03, -0.0000e+00,  1.6108e-03,  3.1013e-03,  0.0000e+00]],\n",
      "\n",
      "         [[-6.3848e-04,  6.7329e-04, -0.0000e+00, -0.0000e+00, -0.0000e+00],\n",
      "          [-1.1644e-03,  3.1509e-03, -2.2602e-03,  4.9057e-03,  9.1553e-03]],\n",
      "\n",
      "         [[ 6.4850e-04, -0.0000e+00,  0.0000e+00, -0.0000e+00,  0.0000e+00],\n",
      "          [ 3.1757e-03,  7.2908e-04, -4.5074e-02,  2.7256e-03, -1.3838e-03]]]],\n",
      "       device='cuda:0', dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "res1 = m.get_residual_stream(\".\")[..., :3, :, :5]\n",
    "mlp1 = m.get_midlayer_activations(\".\")[\"mlp\"][..., :5]\n",
    "print(res1)\n",
    "\n",
    "remove_indices = torch.zeros([m.cfg.n_layers, m.cfg.d_mlp], dtype=bool)\n",
    "remove_indices[0, 1] = True\n",
    "m.hooks.delete_mlp_neurons(remove_indices)\n",
    "\n",
    "print(offset_layer_0.state_dict())\n",
    "res2 = m.get_residual_stream(\".\")[..., :3, :, :5]\n",
    "mlp2 = m.get_midlayer_activations(\".\")[\"mlp\"][..., :5]\n",
    "\n",
    "print((res1-res2)/res1)\n",
    "print((mlp1-mlp2)/mlp1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
