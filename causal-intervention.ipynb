{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loaded nickypro/tinyllama-15m\n",
      " - Registered 6 Attention Layers\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from taker import Model\n",
    "\n",
    "m = Model()\n",
    "\n",
    "vecs = []\n",
    "for i in range(13):\n",
    "    vecs.append( np.load(f\"/home/ubuntu/eloise/vectorLayer{i}.npy\") )\n",
    "vecs = np.array( vecs )\n",
    "normed_vecs = np.zeros_like(vecs)\n",
    "for i in range(len(vecs)):\n",
    "    normed_vecs[i] = vecs[i] / np.linalg.norm(vecs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "genres = [\"code\", \"explanatory\", \"instructional\", \"narrative\", \"speech\"]\n",
    "human_texts = []\n",
    "for genre in genres:\n",
    "    with open(f\"/home/ubuntu/eloise/humanEdited_{genre}.json\") as f:\n",
    "        human_texts.append( json.load( f ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2972158/2505920237.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  vecs = torch.tensor(vecs, device=m.device, dtype=m.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code            ['37.93%', '13.64%', '0.00%', '0.78%', '47.65%']\n",
      "explanatory     ['9.76%', '87.64%', '0.00%', '0.98%', '1.63%']\n",
      "instructional   ['96.13%', '2.81%', '0.00%', '0.38%', '0.68%']\n",
      "narrative       ['17.55%', '61.60%', '1.88%', '17.55%', '1.41%']\n",
      "speech          ['23.94%', '12.04%', '0.00%', '60.48%', '3.54%']\n"
     ]
    }
   ],
   "source": [
    "vecs = torch.tensor(vecs, device=m.device, dtype=m.dtype)\n",
    "\n",
    "layer_norms_typical = {genre: [[] for layer in range(13)] for genre in genres}\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_genre_scores = []\n",
    "\n",
    "    for split, genre in zip(human_texts, genres):\n",
    "        genre_scores = np.array([0 for i in range(5)])\n",
    "        for text in split:\n",
    "            for subtext in text[\"split_text\"]:\n",
    "                res = m.get_residual_stream(subtext[\"text\"]).mean(dim=1)\n",
    "\n",
    "                for layer in [10]:\n",
    "                    idx = torch.argmax( vecs[layer] @ res[layer:layer+1].T )\n",
    "                    genre_scores[idx] += 1\n",
    "\n",
    "                for layer in range(13):\n",
    "                    layer_norms_typical[genre][layer].append(res[layer].norm())\n",
    "        normed_genre_scores = genre_scores / np.sum(genre_scores)\n",
    "        normed_genre_scores = [ f\"{x*100:.2f}%\" for x in normed_genre_scores ]\n",
    "        print(f\"{genre:15s}\", normed_genre_scores)\n",
    "\n",
    "        all_genre_scores.append(normed_genre_scores)\n",
    "\n",
    "all_genre_scores = np.array(all_genre_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instructional': 0, 'explanatory': 1, 'narrative': 2, 'speech': 3, 'code': 4}\n",
      "{0: 'instructional', 1: 'explanatory', 2: 'narrative', 3: 'speech', 4: 'code'}\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax( all_genre_scores, axis=0)\n",
    "\n",
    "id_to_genre = { idx: genres[_id] for idx, _id in enumerate(ids) }\n",
    "genre_to_id = {v:k for k, v in id_to_genre.items()}\n",
    "\n",
    "print(genre_to_id)\n",
    "print(id_to_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.1528\n",
      "1: 0.3005\n",
      "2: 0.6875\n",
      "3: 0.8174\n",
      "4: 1.267\n",
      "5: 1.551\n",
      "6: 1.858\n",
      "7: 2.74\n",
      "8: 3.176\n",
      "9: 4.543\n",
      "10: 4.55\n",
      "11: 6.73\n",
      "12: 71.94\n"
     ]
    }
   ],
   "source": [
    "layer_size = []\n",
    "\n",
    "for layer in range(13):\n",
    "    layer_genre = []\n",
    "    for genre in genres:\n",
    "        layer_genre.append( np.mean([ x.cpu() for x in layer_norms_typical[genre][layer] ]) )\n",
    "        # print( f\"{layer} {genre}:\", np.mean([ x.cpu() for x in layer_norms_typical[genre][layer] ]) )\n",
    "    layer_size.append(np.median(layer_genre))\n",
    "    print(f\"{layer}:\", layer_size[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'attn_o': NeuronFunctionList(\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x NeuronPostBias()\n",
      "  )\n",
      "), 'mlp_out': NeuronFunctionList(\n",
      "  (layers): ModuleList(\n",
      "    (0-5): 6 x NeuronPostBias()\n",
      "  )\n",
      ")}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline       : Alice and Bob were best friends. They did everything together, but one day Bob wanted to play with Alice's\n",
      "instructional  : Alice and Bob are are are are are nice pencil is your paper.\".\"\n",
      " yourself is reach up up\n",
      "explanatory    : Alice and Bob were best friends.  of tough thies. fields of thick snow. snow for many other\n",
      "narrative      : Alice and Bob went their distant forest one day. he had had the heart his heartel layelel and had\n",
      "speech         : Alice and Bob!\"!\" I have a go!\" I have a really!\"!\" I want really!\" I can feel\n",
      "code           : Alice and Bob were two-weed and walked to the park. They were both walking and walking. On the\n",
      "baseline       : Once upon a time, there was a little boy named Timmy. Timmy loved to play outside, but it was\n",
      "instructional  : Once upon a time, Tim is is clean clothes is dry. The table is not is clean your hands is not on\n",
      "explanatory    : Once upon a time, there was a little car. the road that where far part of a part of the ground.\n",
      "narrative      : Once upon a time, a little baby bird me,\" meow meowed in a meadow me meadow. he\n",
      "speech         : Once upon a time, a little birdie a guess how?\" I can have a wise old wise, I need to\n",
      "code           : Once upon a time, there was a little girl named Lily who wanted to call and play with her. She looked\n",
      "baseline       : Bob needs to go to the doctor. He is a nurse and he has to take his medicine. He has\n",
      "instructional  : Bob needs to be dry.\"?\" yourself is dry reach is dry.\".\" Tom is is property yourself is paper plate\n",
      "explanatory    : Bob needs to die. for snow.. in the big snow. made many snow. made parts of the earth\n",
      "narrative      : Bob needs to story in his forest forest. bra meadow meadow me we had never around. and, he\n",
      "speech         : Bob needs to have an adventable!\" I must go!\"!\" I guess I' really need a really luck?\"\n",
      "code           : Bob needs to play. He looked around the kitchen but he saw a door and he said, \"Mom,\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Alice and Bob\",\n",
    "    \"Once upon a time\",\n",
    "    \"Bob needs to\",\n",
    "    \"A huge dragon\",\n",
    "    \"The sky was\"\n",
    "]\n",
    "\n",
    "m.model.config.pad_token_id = m.model.config.eos_token_id\n",
    "print(m.model.config.pad_token_id)\n",
    "\n",
    "print(m.post_biases)\n",
    "\n",
    "\n",
    "text_generations = []\n",
    "for text in texts:\n",
    "    generations = []\n",
    "    text_generations.append(generations)\n",
    "    attn_res = normed_vecs[1::2]\n",
    "\n",
    "    # Clean generation baseline\n",
    "    for layer in range(6):\n",
    "        for thing in [\"mlp_out\", \"attn_o\"]:\n",
    "            h = m.post_biases[thing][layer]\n",
    "            params = h.state_dict()\n",
    "            params[\"param\"] = torch.zeros_like( params[\"param\"] )\n",
    "            h.load_state_dict(params)\n",
    "\n",
    "    generations.append( \"baseline       : \" + \"\".join(m.generate(text, 20)) )\n",
    "\n",
    "    # modified outputs\n",
    "    for class_idx in range(5):\n",
    "        for layer in [1,2,3,4]:\n",
    "            h = m.post_biases[\"attn_o\"][layer]\n",
    "            params = h.state_dict()\n",
    "            params[\"param\"] = torch.tensor(attn_res[layer][class_idx]) * 1.0 * layer_size[1 + 2*layer]\n",
    "            h.load_state_dict(params)\n",
    "\n",
    "        generations.append( f\"{id_to_genre[class_idx]:15s}: \" + \"\".join(m.generate(text, 20)) )\n",
    "\n",
    "    # for generation in generations:\n",
    "    #     print(generation)\n",
    "\n",
    "for texts in text_generations:\n",
    "    for generation in texts:\n",
    "        print(generation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
